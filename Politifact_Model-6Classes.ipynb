{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "532c22af",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2378d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "196073b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f00e6",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "258daf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8492, 7865), Val: (944, 7865), Test: (2360, 7865)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"politifact_factcheck_data.csv\")\n",
    "\n",
    "# Step 1: Filter relevant sources\n",
    "allowed_sources = ['news', 'blog', 'social_media']\n",
    "df = df[df['statement_source'].str.lower().isin(allowed_sources)].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Sentiment using VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['statement'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Step 3: POS ratios\n",
    "def get_pos_features(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    total = len(tokens)\n",
    "    return pd.Series({\n",
    "        'noun_ratio': sum(1 for _, t in tags if t.startswith('NN')) / total if total else 0,\n",
    "        'verb_ratio': sum(1 for _, t in tags if t.startswith('VB')) / total if total else 0,\n",
    "        'pronoun_ratio': sum(1 for _, t in tags if t in ['PRP', 'PRP$', 'WP', 'WP$']) / total if total else 0\n",
    "    })\n",
    "\n",
    "pos_df = df['statement'].apply(get_pos_features)\n",
    "df = pd.concat([df, pos_df], axis=1)\n",
    "\n",
    "# Step 4: Label encoding\n",
    "df['label'] = df['verdict']\n",
    "le = LabelEncoder()\n",
    "df['label_enc'] = le.fit_transform(df['label'])\n",
    "\n",
    "# Step 5: TF-IDF on statements\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(df['statement'])\n",
    "\n",
    "# Step 6: Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(df[['sentiment', 'noun_ratio', 'verb_ratio', 'pronoun_ratio']])\n",
    "\n",
    "# Step 7: Encode categorical metadata\n",
    "df['statement_source'] = df['statement_source'].fillna(\"unknown\")\n",
    "df['statement_originator'] = df['statement_originator'].fillna(\"unknown\")\n",
    "\n",
    "# One-hot encode\n",
    "df_encoded = pd.get_dummies(df[['statement_source', 'statement_originator']], drop_first=True)\n",
    "\n",
    "# Ensure same scale\n",
    "X_categorical = csr_matrix(df_encoded.values)\n",
    "\n",
    "# Step 8: Combine all features\n",
    "X_numeric_sparse = csr_matrix(X_numeric)\n",
    "X = hstack([X_text, X_numeric_sparse, X_categorical])\n",
    "y = df['label_enc']\n",
    "\n",
    "# Step 9: Train-validation-test split (as per paper)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.1, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b5319",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc2354f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Validation Accuracy: 0.3686440677966102\n",
      "Logistic Regression Test Accuracy: 0.37203389830508476\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.68      0.55       748\n",
      "           1       0.23      0.19      0.21       321\n",
      "           2       0.16      0.10      0.13       345\n",
      "           3       0.29      0.33      0.31       320\n",
      "           4       0.53      0.31      0.40       391\n",
      "           5       0.26      0.18      0.22       235\n",
      "\n",
      "    accuracy                           0.37      2360\n",
      "   macro avg       0.32      0.30      0.30      2360\n",
      "weighted avg       0.35      0.37      0.35      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Validation performance\n",
    "y_val_pred = lr.predict(X_val)\n",
    "print(\"LR Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "# Final test performance\n",
    "y_test_pred = lr.predict(X_test)\n",
    "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "492577a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Accuracy: 0.3326271186440678\n",
      "Naive Bayes Test Accuracy: 0.34915254237288135\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.92      0.50       748\n",
      "           1       0.27      0.09      0.13       321\n",
      "           2       0.12      0.01      0.02       345\n",
      "           3       0.37      0.18      0.25       320\n",
      "           4       0.62      0.10      0.18       391\n",
      "           5       0.50      0.03      0.05       235\n",
      "\n",
      "    accuracy                           0.35      2360\n",
      "   macro avg       0.37      0.22      0.19      2360\n",
      "weighted avg       0.37      0.35      0.25      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-do TF-IDF only for NB (exclude scaled metadata)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df['statement'])\n",
    "\n",
    "# Re-split only the TF-IDF features\n",
    "X_tfidf_temp, X_tfidf_test, y_temp, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_tfidf_train, X_tfidf_val, y_train, y_val = train_test_split(X_tfidf_temp, y_temp, test_size=0.1, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Now train Naive Bayes safely\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_tfidf_train, y_train)\n",
    "\n",
    "print(\"NB Validation Accuracy:\", accuracy_score(y_val, nb.predict(X_tfidf_val)))\n",
    "print(\"Naive Bayes Test Accuracy:\", accuracy_score(y_test, nb.predict(X_tfidf_test)))\n",
    "print(classification_report(y_test, nb.predict(X_tfidf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6f5457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.3559322033898305\n",
      "SVM Test Accuracy: 0.3635593220338983\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.67      0.54       748\n",
      "           1       0.22      0.21      0.21       321\n",
      "           2       0.18      0.11      0.13       345\n",
      "           3       0.27      0.28      0.27       320\n",
      "           4       0.51      0.32      0.39       391\n",
      "           5       0.23      0.18      0.20       235\n",
      "\n",
      "    accuracy                           0.36      2360\n",
      "   macro avg       0.31      0.29      0.29      2360\n",
      "weighted avg       0.34      0.36      0.34      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm.predict(X_val)))\n",
    "print(\"SVM Test Accuracy:\", accuracy_score(y_test, svm.predict(X_test)))\n",
    "print(classification_report(y_test, svm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1904133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Validation Accuracy: 0.3093220338983051\n",
      "KNN Test Accuracy: 0.3207627118644068\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.64      0.49       748\n",
      "           1       0.22      0.18      0.20       321\n",
      "           2       0.18      0.12      0.15       345\n",
      "           3       0.26      0.21      0.23       320\n",
      "           4       0.33      0.22      0.26       391\n",
      "           5       0.18      0.10      0.13       235\n",
      "\n",
      "    accuracy                           0.32      2360\n",
      "   macro avg       0.26      0.25      0.24      2360\n",
      "weighted avg       0.29      0.32      0.29      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN Validation Accuracy:\", accuracy_score(y_val, knn.predict(X_val)))\n",
    "print(\"KNN Test Accuracy:\", accuracy_score(y_test, knn.predict(X_test)))\n",
    "print(classification_report(y_test, knn.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0fd8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Validation Accuracy: 0.3294491525423729\n",
      "Decision Tree Test Accuracy: 0.3305084745762712\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.71      0.51       748\n",
      "           1       0.17      0.22      0.19       321\n",
      "           2       0.11      0.01      0.02       345\n",
      "           3       0.23      0.26      0.24       320\n",
      "           4       0.43      0.23      0.30       391\n",
      "           5       0.40      0.01      0.02       235\n",
      "\n",
      "    accuracy                           0.33      2360\n",
      "   macro avg       0.29      0.24      0.21      2360\n",
      "weighted avg       0.31      0.33      0.27      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"DT Validation Accuracy:\", accuracy_score(y_val, dt.predict(X_val)))\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test, dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41abd62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Validation Accuracy: 0.3411016949152542\n",
      "AdaBoost Test Accuracy: 0.3389830508474576\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.80      0.49       748\n",
      "           1       0.26      0.04      0.07       321\n",
      "           2       0.00      0.00      0.00       345\n",
      "           3       0.29      0.34      0.31       320\n",
      "           4       0.33      0.19      0.24       391\n",
      "           5       0.29      0.01      0.02       235\n",
      "\n",
      "    accuracy                           0.34      2360\n",
      "   macro avg       0.25      0.23      0.19      2360\n",
      "weighted avg       0.27      0.34      0.25      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "print(\"AB Validation Accuracy:\", accuracy_score(y_val, ab.predict(X_val)))\n",
    "print(\"AdaBoost Test Accuracy:\", accuracy_score(y_test, ab.predict(X_test)))\n",
    "print(classification_report(y_test, ab.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b012121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Validation Accuracy: 0.3463983050847458\n",
      "XGBoost Test Accuracy: 0.3580508474576271\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53       748\n",
      "           1       0.21      0.17      0.19       321\n",
      "           2       0.20      0.10      0.14       345\n",
      "           3       0.27      0.29      0.28       320\n",
      "           4       0.51      0.29      0.37       391\n",
      "           5       0.24      0.16      0.19       235\n",
      "\n",
      "    accuracy                           0.36      2360\n",
      "   macro avg       0.31      0.28      0.28      2360\n",
      "weighted avg       0.34      0.36      0.33      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGB Validation Accuracy:\", accuracy_score(y_val, xgb.predict(X_val)))\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test, xgb.predict(X_test)))\n",
    "print(classification_report(y_test, xgb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb6c85",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuning + K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0d62386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.5994842503189409}\n",
      "Logistic Regression 5-Fold Accuracy: 0.3762 (+/- 0.0104)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter search space\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Step 1: Randomized Search for best hyperparameters\n",
    "search_lr = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search_lr.fit(X, y)\n",
    "print(\"Best Logistic Regression Params:\", search_lr.best_params_)\n",
    "\n",
    "# Step 2: Build final model with best params\n",
    "best_lr = LogisticRegression(**search_lr.best_params_, max_iter=1000)\n",
    "\n",
    "# Step 3: Perform 5-Fold CV using best params\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(best_lr, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Logistic Regression 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ed14d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NB Params: {'alpha': 0.6373684210526316}\n",
      "Naive Bayes 5-Fold Accuracy: 0.3525 (+/- 0.0089)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "# TF-IDF features only (recomputed to ensure clean shape)\n",
    "tfidf_nb = TfidfVectorizer(max_features=5000)\n",
    "X_nb = tfidf_nb.fit_transform(df['statement'])\n",
    "\n",
    "# Parameter grid\n",
    "param_dist = {\n",
    "    'alpha': np.linspace(0.01, 1.5, 20)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning\n",
    "search_nb = RandomizedSearchCV(MultinomialNB(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42)\n",
    "search_nb.fit(X_nb, y)\n",
    "print(\"Best NB Params:\", search_nb.best_params_)\n",
    "\n",
    "# Final model\n",
    "best_nb = MultinomialNB(**search_nb.best_params_)\n",
    "\n",
    "# 5-Fold CV\n",
    "scores = cross_val_score(best_nb, X_nb, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Naive Bayes 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09c0951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Params: {'kernel': 'linear', 'C': 0.1668100537200059}\n",
      "SVM 5-Fold Accuracy: 0.3679 (+/- 0.0080)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "search_svm = RandomizedSearchCV(SVC(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_svm.fit(X, y)\n",
    "print(\"Best SVM Params:\", search_svm.best_params_)\n",
    "\n",
    "best_svm = SVC(**search_svm.best_params_)\n",
    "scores = cross_val_score(best_svm, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"SVM 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8802ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Params: {'weights': 'uniform', 'n_neighbors': 11, 'metric': 'manhattan'}\n",
      "KNN 5-Fold Accuracy: 0.3267 (+/- 0.0052)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': list(range(3, 15)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "search_knn = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist,\n",
    "                                 n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_knn.fit(X, y)\n",
    "print(\"Best KNN Params:\", search_knn.best_params_)\n",
    "\n",
    "best_knn = KNeighborsClassifier(**search_knn.best_params_)\n",
    "scores = cross_val_score(best_knn, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"KNN 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "592e56c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT Params: {'min_samples_split': 2, 'max_depth': 13, 'criterion': 'gini'}\n",
      "Decision Tree 5-Fold Accuracy: 0.3397 (+/- 0.0049)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': list(range(3, 20)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "search_dt = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_dt.fit(X, y)\n",
    "print(\"Best DT Params:\", search_dt.best_params_)\n",
    "\n",
    "best_dt = DecisionTreeClassifier(**search_dt.best_params_)\n",
    "scores = cross_val_score(best_dt, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Decision Tree 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e04a6d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': None}\n",
      "Random Forest 5-Fold Accuracy: 0.3599 (+/- 0.0062)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_rf.fit(X, y)\n",
    "print(\"Best RF Params:\", search_rf.best_params_)\n",
    "\n",
    "best_rf = RandomForestClassifier(**search_rf.best_params_)\n",
    "scores = cross_val_score(best_rf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Random Forest 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c335fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Params: {'n_estimators': 200, 'learning_rate': 0.78}\n",
      "AdaBoost 5-Fold Accuracy: 0.3445 (+/- 0.0099)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': np.linspace(0.01, 1.0, 10)\n",
    "}\n",
    "\n",
    "search_ab = RandomizedSearchCV(AdaBoostClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_ab.fit(X, y)\n",
    "print(\"Best AdaBoost Params:\", search_ab.best_params_)\n",
    "\n",
    "best_ab = AdaBoostClassifier(**search_ab.best_params_)\n",
    "scores = cross_val_score(best_ab, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"AdaBoost 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "795ad4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Params: {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 3, 'learning_rate': 0.1}\n",
      "XGBoost 5-Fold Accuracy: 0.3545 (+/- 0.0096)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "search_xgb = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                                param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_xgb.fit(X, y)\n",
    "print(\"Best XGB Params:\", search_xgb.best_params_)\n",
    "\n",
    "best_xgb = XGBClassifier(**search_xgb.best_params_, use_label_encoder=False, eval_metric='logloss')\n",
    "scores = cross_val_score(best_xgb, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"XGBoost 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dea22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
