{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2957720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"politifact_factcheck_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6135c423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>verdict</th>\n",
       "      <th>statement_originator</th>\n",
       "      <th>statement</th>\n",
       "      <th>statement_date</th>\n",
       "      <th>statement_source</th>\n",
       "      <th>factchecker</th>\n",
       "      <th>factcheck_date</th>\n",
       "      <th>factcheck_analysis_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>true</td>\n",
       "      <td>Barack Obama</td>\n",
       "      <td>John McCain opposed bankruptcy protections for...</td>\n",
       "      <td>6/11/2008</td>\n",
       "      <td>speech</td>\n",
       "      <td>Adriel Bettelheim</td>\n",
       "      <td>6/16/2008</td>\n",
       "      <td>https://www.politifact.com/factchecks/2008/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>false</td>\n",
       "      <td>Matt Gaetz</td>\n",
       "      <td>\"Bennie Thompson actively cheer-led riots in t...</td>\n",
       "      <td>6/7/2022</td>\n",
       "      <td>television</td>\n",
       "      <td>Yacob Reyes</td>\n",
       "      <td>6/13/2022</td>\n",
       "      <td>https://www.politifact.com/factchecks/2022/jun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mostly-true</td>\n",
       "      <td>Kelly Ayotte</td>\n",
       "      <td>Says Maggie Hassan was \"out of state on 30 day...</td>\n",
       "      <td>5/18/2016</td>\n",
       "      <td>news</td>\n",
       "      <td>Clay Wirestone</td>\n",
       "      <td>5/27/2016</td>\n",
       "      <td>https://www.politifact.com/factchecks/2016/may...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>false</td>\n",
       "      <td>Bloggers</td>\n",
       "      <td>\"BUSTED: CDC Inflated COVID Numbers, Accused o...</td>\n",
       "      <td>2/1/2021</td>\n",
       "      <td>blog</td>\n",
       "      <td>Madison Czopek</td>\n",
       "      <td>2/5/2021</td>\n",
       "      <td>https://www.politifact.com/factchecks/2021/feb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>half-true</td>\n",
       "      <td>Bobby Jindal</td>\n",
       "      <td>\"I'm the only (Republican) candidate that has ...</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>television</td>\n",
       "      <td>Linda Qiu</td>\n",
       "      <td>8/30/2015</td>\n",
       "      <td>https://www.politifact.com/factchecks/2015/aug...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       verdict statement_originator  \\\n",
       "0         true         Barack Obama   \n",
       "1        false           Matt Gaetz   \n",
       "2  mostly-true         Kelly Ayotte   \n",
       "3        false             Bloggers   \n",
       "4    half-true         Bobby Jindal   \n",
       "\n",
       "                                           statement statement_date  \\\n",
       "0  John McCain opposed bankruptcy protections for...      6/11/2008   \n",
       "1  \"Bennie Thompson actively cheer-led riots in t...       6/7/2022   \n",
       "2  Says Maggie Hassan was \"out of state on 30 day...      5/18/2016   \n",
       "3  \"BUSTED: CDC Inflated COVID Numbers, Accused o...       2/1/2021   \n",
       "4  \"I'm the only (Republican) candidate that has ...      8/30/2015   \n",
       "\n",
       "  statement_source        factchecker factcheck_date  \\\n",
       "0           speech  Adriel Bettelheim      6/16/2008   \n",
       "1       television        Yacob Reyes      6/13/2022   \n",
       "2             news     Clay Wirestone      5/27/2016   \n",
       "3             blog     Madison Czopek       2/5/2021   \n",
       "4       television          Linda Qiu      8/30/2015   \n",
       "\n",
       "                             factcheck_analysis_link  \n",
       "0  https://www.politifact.com/factchecks/2008/jun...  \n",
       "1  https://www.politifact.com/factchecks/2022/jun...  \n",
       "2  https://www.politifact.com/factchecks/2016/may...  \n",
       "3  https://www.politifact.com/factchecks/2021/feb...  \n",
       "4  https://www.politifact.com/factchecks/2015/aug...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c5e43d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21152, 8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a5d8ddd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0              speech\n",
       "1          television\n",
       "2                news\n",
       "3                blog\n",
       "4          television\n",
       "             ...     \n",
       "21147          speech\n",
       "21148    social_media\n",
       "21149            news\n",
       "21150            blog\n",
       "21151    social_media\n",
       "Name: statement_source, Length: 21152, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfq=df['statement_source']\n",
    "dfq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bdaf3776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['speech', 'television', 'news', 'blog', 'other', 'social_media',\n",
       "       'advertisement', 'campaign', 'meeting', 'radio', 'email',\n",
       "       'testimony', 'statement'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfq.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6502ae0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11795\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "for i in range(21151):\n",
    "    if dfq[i]==\"news\" or dfq[i]==\"blog\" or dfq[i]==\"social_media\":\n",
    "        count=count+1\n",
    "print(count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bd859818",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21152, 8)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532c22af",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2378d03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import hstack, csr_matrix\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "196073b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     C:\\Users\\Asus\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "673f00e6",
   "metadata": {},
   "source": [
    "#### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "258daf58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (8492, 7865), Val: (944, 7865), Test: (2360, 7865)\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"politifact_factcheck_data.csv\")\n",
    "\n",
    "# Step 1: Filter relevant sources\n",
    "allowed_sources = ['news', 'blog', 'social_media']\n",
    "df = df[df['statement_source'].str.lower().isin(allowed_sources)].reset_index(drop=True)\n",
    "\n",
    "# Step 2: Sentiment using VADER\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "df['sentiment'] = df['statement'].apply(lambda x: analyzer.polarity_scores(x)['compound'])\n",
    "\n",
    "# Step 3: POS ratios\n",
    "def get_pos_features(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tags = pos_tag(tokens)\n",
    "    total = len(tokens)\n",
    "    return pd.Series({\n",
    "        'noun_ratio': sum(1 for _, t in tags if t.startswith('NN')) / total if total else 0,\n",
    "        'verb_ratio': sum(1 for _, t in tags if t.startswith('VB')) / total if total else 0,\n",
    "        'pronoun_ratio': sum(1 for _, t in tags if t in ['PRP', 'PRP$', 'WP', 'WP$']) / total if total else 0\n",
    "    })\n",
    "\n",
    "pos_df = df['statement'].apply(get_pos_features)\n",
    "df = pd.concat([df, pos_df], axis=1)\n",
    "\n",
    "# Step 4: Label encoding\n",
    "df['label'] = df['verdict'].apply(lambda x: 'real' if 'true' in x.lower() else 'fake')\n",
    "le = LabelEncoder()\n",
    "df['label_enc'] = le.fit_transform(df['label'])\n",
    "\n",
    "# Step 5: TF-IDF on statements\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_text = tfidf.fit_transform(df['statement'])\n",
    "\n",
    "# Step 6: Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_numeric = scaler.fit_transform(df[['sentiment', 'noun_ratio', 'verb_ratio', 'pronoun_ratio']])\n",
    "\n",
    "# Step 7: Encode categorical metadata\n",
    "df['statement_source'] = df['statement_source'].fillna(\"unknown\")\n",
    "df['statement_originator'] = df['statement_originator'].fillna(\"unknown\")\n",
    "\n",
    "# One-hot encode\n",
    "df_encoded = pd.get_dummies(df[['statement_source', 'statement_originator']], drop_first=True)\n",
    "\n",
    "# Ensure same scale\n",
    "X_categorical = csr_matrix(df_encoded.values)\n",
    "\n",
    "# Step 8: Combine all features\n",
    "X_numeric_sparse = csr_matrix(X_numeric)\n",
    "X = hstack([X_text, X_numeric_sparse, X_categorical])\n",
    "y = df['label_enc']\n",
    "\n",
    "# Step 9: Train-validation-test split (as per paper)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.1, random_state=42, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(f\"Train: {X_train.shape}, Val: {X_val.shape}, Test: {X_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b5319",
   "metadata": {},
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cc2354f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Validation Accuracy: 0.7129237288135594\n",
      "Logistic Regression Test Accuracy: 0.7444915254237288\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      1484\n",
      "           1       0.66      0.64      0.65       876\n",
      "\n",
      "    accuracy                           0.74      2360\n",
      "   macro avg       0.73      0.72      0.72      2360\n",
      "weighted avg       0.74      0.74      0.74      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Validation performance\n",
    "y_val_pred = lr.predict(X_val)\n",
    "print(\"LR Validation Accuracy:\", accuracy_score(y_val, y_val_pred))\n",
    "\n",
    "# Final test performance\n",
    "y_test_pred = lr.predict(X_test)\n",
    "print(\"Logistic Regression Test Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "492577a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB Validation Accuracy: 0.698093220338983\n",
      "Naive Bayes Test Accuracy: 0.7203389830508474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      1484\n",
      "           1       0.66      0.50      0.57       876\n",
      "\n",
      "    accuracy                           0.72      2360\n",
      "   macro avg       0.70      0.68      0.68      2360\n",
      "weighted avg       0.71      0.72      0.71      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Re-do TF-IDF only for NB (exclude scaled metadata)\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_tfidf = tfidf.fit_transform(df['statement'])\n",
    "\n",
    "# Re-split only the TF-IDF features\n",
    "X_tfidf_temp, X_tfidf_test, y_temp, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42, stratify=y)\n",
    "X_tfidf_train, X_tfidf_val, y_train, y_val = train_test_split(X_tfidf_temp, y_temp, test_size=0.1, random_state=42, stratify=y_temp)\n",
    "\n",
    "# Now train Naive Bayes safely\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_tfidf_train, y_train)\n",
    "\n",
    "print(\"NB Validation Accuracy:\", accuracy_score(y_val, nb.predict(X_tfidf_val)))\n",
    "print(\"Naive Bayes Test Accuracy:\", accuracy_score(y_test, nb.predict(X_tfidf_test)))\n",
    "print(classification_report(y_test, nb.predict(X_tfidf_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c6f5457d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Validation Accuracy: 0.701271186440678\n",
      "SVM Test Accuracy: 0.7288135593220338\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.80      0.79      1484\n",
      "           1       0.64      0.62      0.63       876\n",
      "\n",
      "    accuracy                           0.73      2360\n",
      "   macro avg       0.71      0.71      0.71      2360\n",
      "weighted avg       0.73      0.73      0.73      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "svm = SVC(kernel='linear', C=1.0)\n",
    "svm.fit(X_train, y_train)\n",
    "\n",
    "print(\"SVM Validation Accuracy:\", accuracy_score(y_val, svm.predict(X_val)))\n",
    "print(\"SVM Test Accuracy:\", accuracy_score(y_test, svm.predict(X_test)))\n",
    "print(classification_report(y_test, svm.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1904133d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Validation Accuracy: 0.6896186440677966\n",
      "KNN Test Accuracy: 0.6953389830508474\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.81      0.77      1484\n",
      "           1       0.61      0.50      0.55       876\n",
      "\n",
      "    accuracy                           0.70      2360\n",
      "   macro avg       0.67      0.65      0.66      2360\n",
      "weighted avg       0.69      0.70      0.69      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "print(\"KNN Validation Accuracy:\", accuracy_score(y_val, knn.predict(X_val)))\n",
    "print(\"KNN Test Accuracy:\", accuracy_score(y_test, knn.predict(X_test)))\n",
    "print(classification_report(y_test, knn.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3e0fd8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DT Validation Accuracy: 0.7002118644067796\n",
      "Decision Tree Test Accuracy: 0.6826271186440678\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.73      0.74      1484\n",
      "           1       0.57      0.60      0.58       876\n",
      "\n",
      "    accuracy                           0.68      2360\n",
      "   macro avg       0.66      0.67      0.66      2360\n",
      "weighted avg       0.69      0.68      0.68      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=10)\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "print(\"DT Validation Accuracy:\", accuracy_score(y_val, dt.predict(X_val)))\n",
    "print(\"Decision Tree Test Accuracy:\", accuracy_score(y_test, dt.predict(X_test)))\n",
    "print(classification_report(y_test, dt.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "41abd62b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AB Validation Accuracy: 0.7108050847457628\n",
      "AdaBoost Test Accuracy: 0.6923728813559322\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.79      0.76      1484\n",
      "           1       0.60      0.52      0.56       876\n",
      "\n",
      "    accuracy                           0.69      2360\n",
      "   macro avg       0.67      0.66      0.66      2360\n",
      "weighted avg       0.69      0.69      0.69      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ab = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "ab.fit(X_train, y_train)\n",
    "\n",
    "print(\"AB Validation Accuracy:\", accuracy_score(y_val, ab.predict(X_val)))\n",
    "print(\"AdaBoost Test Accuracy:\", accuracy_score(y_test, ab.predict(X_test)))\n",
    "print(classification_report(y_test, ab.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b012121b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGB Validation Accuracy: 0.7182203389830508\n",
      "XGBoost Test Accuracy: 0.7237288135593221\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.78      1484\n",
      "           1       0.64      0.60      0.62       876\n",
      "\n",
      "    accuracy                           0.72      2360\n",
      "   macro avg       0.70      0.70      0.70      2360\n",
      "weighted avg       0.72      0.72      0.72      2360\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb.fit(X_train, y_train)\n",
    "\n",
    "print(\"XGB Validation Accuracy:\", accuracy_score(y_val, xgb.predict(X_val)))\n",
    "print(\"XGBoost Test Accuracy:\", accuracy_score(y_test, xgb.predict(X_test)))\n",
    "print(classification_report(y_test, xgb.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d6880b9",
   "metadata": {},
   "source": [
    "#### Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "5173b28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best LR Params: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.5994842503189409}\n",
      "Tuned Logistic Regression Accuracy: 0.7470338983050847\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "search_lr = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_lr.fit(X_train, y_train)\n",
    "print(\"Best LR Params:\", search_lr.best_params_)\n",
    "\n",
    "y_pred = search_lr.predict(X_test)\n",
    "print(\"Tuned Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6515a46a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NB Params: {'alpha': 0.25555555555555554}\n",
      "Tuned Naive Bayes Accuracy: 0.7161016949152542\n"
     ]
    }
   ],
   "source": [
    "# Use only X_tfidf as done in previous block\n",
    "param_dist = {\n",
    "    'alpha': np.linspace(0.1, 1.5, 10)\n",
    "}\n",
    "\n",
    "search_nb = RandomizedSearchCV(MultinomialNB(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_nb.fit(X_tfidf_train, y_train)\n",
    "print(\"Best NB Params:\", search_nb.best_params_)\n",
    "\n",
    "y_pred = search_nb.predict(X_tfidf_test)\n",
    "print(\"Tuned Naive Bayes Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6c391708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Params: {'kernel': 'linear', 'C': 0.1668100537200059}\n",
      "Tuned SVM Accuracy: 0.7436440677966102\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "search_svm = RandomizedSearchCV(SVC(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_svm.fit(X_train, y_train)\n",
    "print(\"Best SVM Params:\", search_svm.best_params_)\n",
    "\n",
    "y_pred = search_svm.predict(X_test)\n",
    "print(\"Tuned SVM Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5873ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Params: {'weights': 'uniform', 'n_neighbors': 5, 'metric': 'euclidean'}\n",
      "Tuned KNN Accuracy: 0.6953389830508474\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_neighbors': list(range(3, 21)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "search_knn = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist,\n",
    "                                 n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_knn.fit(X_train, y_train)\n",
    "print(\"Best KNN Params:\", search_knn.best_params_)\n",
    "\n",
    "y_pred = search_knn.predict(X_test)\n",
    "print(\"Tuned KNN Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cb4eef9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT Params: {'min_samples_split': 2, 'max_depth': 13, 'criterion': 'gini'}\n",
      "Tuned Decision Tree Accuracy: 0.6724576271186441\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'max_depth': list(range(3, 20)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "search_dt = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_dt.fit(X_train, y_train)\n",
    "print(\"Best DT Params:\", search_dt.best_params_)\n",
    "\n",
    "y_pred = search_dt.predict(X_test)\n",
    "print(\"Tuned Decision Tree Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "44360bd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'n_estimators': 100, 'min_samples_split': 2, 'max_depth': None}\n",
      "Tuned Random Forest Accuracy: 0.7203389830508474\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_rf.fit(X_train, y_train)\n",
    "print(\"Best RF Params:\", search_rf.best_params_)\n",
    "\n",
    "y_pred = search_rf.predict(X_test)\n",
    "print(\"Tuned Random Forest Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "4c0d902a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Params: {'n_estimators': 200, 'learning_rate': 0.56}\n",
      "Tuned AdaBoost Accuracy: 0.6953389830508474\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': np.linspace(0.01, 1.0, 10)\n",
    "}\n",
    "\n",
    "search_ab = RandomizedSearchCV(AdaBoostClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_ab.fit(X_train, y_train)\n",
    "print(\"Best AdaBoost Params:\", search_ab.best_params_)\n",
    "\n",
    "y_pred = search_ab.predict(X_test)\n",
    "print(\"Tuned AdaBoost Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f73fd5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Params: {'subsample': 1.0, 'n_estimators': 200, 'max_depth': 6, 'learning_rate': 0.3}\n",
      "Tuned XGBoost Accuracy: 0.7156779661016949\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "search_xgb = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                                param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_xgb.fit(X_train, y_train)\n",
    "print(\"Best XGB Params:\", search_xgb.best_params_)\n",
    "\n",
    "y_pred = search_xgb.predict(X_test)\n",
    "print(\"Tuned XGBoost Accuracy:\", accuracy_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb04dc64",
   "metadata": {},
   "source": [
    "#### K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7ca863e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d6fd9aa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7422 (+/- 0.0062)\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Logistic Regression Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "639dad74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy: 0.7158 (+/- 0.0084)\n"
     ]
    }
   ],
   "source": [
    "# Naive Bayes requires only non-negative input\n",
    "X_nb = tfidf.fit_transform(df['statement'])\n",
    "\n",
    "model = MultinomialNB()\n",
    "scores = cross_val_score(model, X_nb, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Naive Bayes Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83357e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy: 0.7313 (+/- 0.0038)\n"
     ]
    }
   ],
   "source": [
    "model = SVC(kernel='linear')\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"SVM Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "14a06c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 0.6895 (+/- 0.0060)\n"
     ]
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"KNN Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "793b1450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy: 0.6872 (+/- 0.0101)\n"
     ]
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth=10)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Decision Tree Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "db0be6c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7152 (+/- 0.0053)\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Random Forest Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "94c28b4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.6896 (+/- 0.0049)\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"AdaBoost Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ca55361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.7167 (+/- 0.0104)\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "scores = cross_val_score(model, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"XGBoost Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4640639",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86846067",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aedb6c85",
   "metadata": {},
   "source": [
    "#### HyperParameter Tuning + K-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c0d62386",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Logistic Regression Params: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.5994842503189409}\n",
      "Logistic Regression 5-Fold Accuracy: 0.7429 (+/- 0.0061)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score, StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "# Define parameter search space\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'solver': ['lbfgs', 'liblinear'],\n",
    "    'penalty': ['l2']\n",
    "}\n",
    "\n",
    "# Step 1: Randomized Search for best hyperparameters\n",
    "search_lr = RandomizedSearchCV(\n",
    "    LogisticRegression(max_iter=1000),\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=10,\n",
    "    scoring='accuracy',\n",
    "    cv=3,\n",
    "    n_jobs=-1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "search_lr.fit(X, y)\n",
    "print(\"Best Logistic Regression Params:\", search_lr.best_params_)\n",
    "\n",
    "# Step 2: Build final model with best params\n",
    "best_lr = LogisticRegression(**search_lr.best_params_, max_iter=1000)\n",
    "\n",
    "# Step 3: Perform 5-Fold CV using best params\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "scores = cross_val_score(best_lr, X, y, cv=cv, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "print(f\"Logistic Regression 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0ed14d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best NB Params: {'alpha': 0.40210526315789474}\n",
      "Naive Bayes 5-Fold Accuracy: 0.7143 (+/- 0.0080)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
    "\n",
    "# TF-IDF features only (recomputed to ensure clean shape)\n",
    "tfidf_nb = TfidfVectorizer(max_features=5000)\n",
    "X_nb = tfidf_nb.fit_transform(df['statement'])\n",
    "\n",
    "# Parameter grid\n",
    "param_dist = {\n",
    "    'alpha': np.linspace(0.01, 1.5, 20)\n",
    "}\n",
    "\n",
    "# Hyperparameter tuning\n",
    "search_nb = RandomizedSearchCV(MultinomialNB(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42)\n",
    "search_nb.fit(X_nb, y)\n",
    "print(\"Best NB Params:\", search_nb.best_params_)\n",
    "\n",
    "# Final model\n",
    "best_nb = MultinomialNB(**search_nb.best_params_)\n",
    "\n",
    "# 5-Fold CV\n",
    "scores = cross_val_score(best_nb, X_nb, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Naive Bayes 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09c0951b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best SVM Params: {'kernel': 'linear', 'C': 0.1668100537200059}\n",
      "SVM 5-Fold Accuracy: 0.7459 (+/- 0.0067)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_dist = {\n",
    "    'C': np.logspace(-3, 2, 10),\n",
    "    'kernel': ['linear', 'rbf']\n",
    "}\n",
    "\n",
    "search_svm = RandomizedSearchCV(SVC(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_svm.fit(X, y)\n",
    "print(\"Best SVM Params:\", search_svm.best_params_)\n",
    "\n",
    "best_svm = SVC(**search_svm.best_params_)\n",
    "scores = cross_val_score(best_svm, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"SVM 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "8802ac3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best KNN Params: {'weights': 'distance', 'n_neighbors': 12, 'metric': 'euclidean'}\n",
      "KNN 5-Fold Accuracy: 0.6896 (+/- 0.0079)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_neighbors': list(range(3, 15)),\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'metric': ['euclidean', 'manhattan']\n",
    "}\n",
    "\n",
    "search_knn = RandomizedSearchCV(KNeighborsClassifier(), param_distributions=param_dist,\n",
    "                                 n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_knn.fit(X, y)\n",
    "print(\"Best KNN Params:\", search_knn.best_params_)\n",
    "\n",
    "best_knn = KNeighborsClassifier(**search_knn.best_params_)\n",
    "scores = cross_val_score(best_knn, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"KNN 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "592e56c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best DT Params: {'min_samples_split': 5, 'max_depth': 6, 'criterion': 'gini'}\n",
      "Decision Tree 5-Fold Accuracy: 0.6890 (+/- 0.0095)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'max_depth': list(range(3, 20)),\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'criterion': ['gini', 'entropy']\n",
    "}\n",
    "\n",
    "search_dt = RandomizedSearchCV(DecisionTreeClassifier(), param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_dt.fit(X, y)\n",
    "print(\"Best DT Params:\", search_dt.best_params_)\n",
    "\n",
    "best_dt = DecisionTreeClassifier(**search_dt.best_params_)\n",
    "scores = cross_val_score(best_dt, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Decision Tree 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e04a6d4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RF Params: {'n_estimators': 300, 'min_samples_split': 10, 'max_depth': None}\n",
      "Random Forest 5-Fold Accuracy: 0.7184 (+/- 0.0035)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10]\n",
    "}\n",
    "\n",
    "search_rf = RandomizedSearchCV(RandomForestClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_rf.fit(X, y)\n",
    "print(\"Best RF Params:\", search_rf.best_params_)\n",
    "\n",
    "best_rf = RandomForestClassifier(**search_rf.best_params_)\n",
    "scores = cross_val_score(best_rf, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"Random Forest 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5c335fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best AdaBoost Params: {'n_estimators': 200, 'learning_rate': 0.78}\n",
      "AdaBoost 5-Fold Accuracy: 0.6909 (+/- 0.0052)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': np.linspace(0.01, 1.0, 10)\n",
    "}\n",
    "\n",
    "search_ab = RandomizedSearchCV(AdaBoostClassifier(), param_distributions=param_dist,\n",
    "                               n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_ab.fit(X, y)\n",
    "print(\"Best AdaBoost Params:\", search_ab.best_params_)\n",
    "\n",
    "best_ab = AdaBoostClassifier(**search_ab.best_params_)\n",
    "scores = cross_val_score(best_ab, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"AdaBoost 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "795ad4ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best XGB Params: {'subsample': 0.7, 'n_estimators': 100, 'max_depth': 6, 'learning_rate': 0.1}\n",
      "XGBoost 5-Fold Accuracy: 0.7197 (+/- 0.0073)\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.7, 1.0]\n",
    "}\n",
    "\n",
    "search_xgb = RandomizedSearchCV(XGBClassifier(use_label_encoder=False, eval_metric='logloss'),\n",
    "                                param_distributions=param_dist,\n",
    "                                n_iter=10, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
    "search_xgb.fit(X, y)\n",
    "print(\"Best XGB Params:\", search_xgb.best_params_)\n",
    "\n",
    "best_xgb = XGBClassifier(**search_xgb.best_params_, use_label_encoder=False, eval_metric='logloss')\n",
    "scores = cross_val_score(best_xgb, X, y, cv=cv, scoring='accuracy')\n",
    "print(f\"XGBoost 5-Fold Accuracy: {scores.mean():.4f} (+/- {scores.std():.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83dea22e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
